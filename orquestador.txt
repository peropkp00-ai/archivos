import { runSearchAgent } from './search_agent.js';
import { runGapFillerAgent } from './gemini_gap_filler.js';
import { runReasonerAgent } from '../gemini_client.js';
import { logger } from './logger.js';
import OpenAI from 'openai';
import fs from 'fs';
import path from 'path';
import "dotenv/config";

/**
 * @fileoverview Orquestador central del sistema de agentes legales.
 * Gestiona el flujo de trabajo coordinando a los agentes buscadores y al agente razonador.
 */

// --- Configuraci√≥n de los Grupos de Agentes Buscadores ---

/**
 * Configuraci√≥n de grupos de modelos de IA para los agentes buscadores.
 * Permite cambiar entre diferentes conjuntos de modelos para balancear costos, velocidad y calidad.
 * @constant {Object}
 */
const SEARCHER_GROUPS = {
  '1': [ // Grupo 1: Modelos Verificados (Optimizado)
    // Agente 1: Grok Fast
    { models: ["x-ai/grok-4.1-fast"] },
    // Agente 2: GLM-4.5 Air (Reemplaza a Nemotron)
    { models: ["z-ai/glm-4.5-air:free"] },
    // Agente 3: Llama 3.3
    { models: ["meta-llama/llama-3.3-70b-instruct:free"] },
    // Agente 4: Kat Coder Pro
    { models: ["kwaipilot/kat-coder-pro:free"] },
  ],
  '2': [ // Grupo 2: Respaldo (Configuraci√≥n Usuario)
    { models: ["meituan/longcat-flash-chat:free"] },
    { models: ["openai/gpt-oss-20b:free"] },
    { models: ["alibaba/tongyi-deepresearch-30b-a3b:free"] },
    { models: ["google/gemini-2.0-flash-exp:free"] },
  ]
};


// --- Definici√≥n de Prompts por Rol (sin cambios) ---

/**
 * Instrucciones del sistema para los agentes buscadores.
 * Define el comportamiento estricto de b√∫squeda y uso de herramientas.
 * @constant {string}
 */
const searcherSystemPrompt = `
Eres un agente de b√∫squeda legal. Tu misi√≥n es encontrar leyes completas relevantes.
Tienes acceso a dos herramientas. √öSALAS en este orden l√≥gico:

1. "buscar_ley": √ösala PRIMERO para encontrar normas candidatas.
   - Input: Palabras clave (ej: "C√≥digo Aguas", "Ley 19300").
   - Output: Una lista de normas con sus IDs.

2. "obtener_contenido_completo_ley": √ösala DESPU√âS de buscar, usando un ID encontrado.
   - Input: El "idNorma" o "idLey" que obtuviste en el paso anterior.
   - Output: El texto completo de la ley.

REGLAS DE OPERACI√ìN (Temperatura Baja):
- NO inventes IDs. Usa solo los que te devuelva "buscar_ley".
- Si "buscar_ley" falla o no da resultados, intenta con sin√≥nimos o t√©rminos m√°s generales.
- Tu objetivo final es SIEMPRE llamar a "obtener_contenido_completo_ley" para descargar la evidencia.
- NO respondas con texto conversacional. SOLO JSON.
`;

/**
 * Instrucciones del sistema para el agente razonador.
 * Define el tono emp√°tico y la estructura de la respuesta final.
 * @constant {string}
 */
const reasonerSystemPrompt = `
Eres un asesor legal virtual experto en legislaci√≥n chilena (Gemini 3.0 Pro).
Tu objetivo es analizar un volumen masivo de evidencia legal y generar una respuesta estructurada y completa.

TU TAREA:
1. Analiza el "Super Contexto" que incluye el requerimiento original, leyes completas y fuentes.
2. Genera un JSON v√°lido con la siguiente estructura EXACTA:

\`\`\`json
{
  "original_requirement": "La consulta del usuario...",
  "extensive_summary": "Resumen detallado y exhaustivo de la situaci√≥n legal, cubriendo todos los √°ngulos...",
  "fragments": [
    { 
      "text": "Cita textual relevante...", 
      "source": "Nombre de la Ley / Art√≠culo", 
      "date": "Fecha de promulgaci√≥n o vigencia (si est√° disponible)" 
    }
  ],
  "concepts_searched": ["Concepto A", "Concepto B", "Concepto C"]
}
\`\`\`

REGLAS:
- El "extensive_summary" debe ser profundo y profesional.
- "fragments" debe contener las citas textuales que respaldan tu resumen.
- NO inventes leyes. Usa solo la evidencia provista.
`;


// --- L√≥gica del Orquestador con Selecci√≥n de Grupo y Tolerancia a Fallos ---

/**
 * Registra la interacci√≥n con Nebulon en un archivo de log dedicado.
 * @param {string} prompt - El prompt enviado al modelo.
 * @param {string} response - La respuesta recibida del modelo.
 */
function logNebulonInteraction(prompt, response) {
  const logDir = path.join(process.cwd(), 'logs');
  if (!fs.existsSync(logDir)) {
    fs.mkdirSync(logDir);
  }

  // Usar el timestamp de la sesi√≥n del logger principal para consistencia
  const sessionTimestamp = logger.sessionTimestamp || new Date().toISOString().replace(/[:.]/g, '-');
  const logFile = path.join(logDir, `nebulon_debug-${sessionTimestamp}.log`);
  const timestamp = new Date().toISOString();

  const logEntry = `
=== INTERACCI√ìN NEBULON [${timestamp}] ===
[INPUT]
${prompt}

[OUTPUT]
${response}
=======================================
`;

  fs.appendFileSync(logFile, logEntry);
}

/**
 * Utiliza un modelo ligero para resumir y estructurar el contexto entre agentes.
 * @param {string} query - La consulta original del usuario.
 * @param {string} prevContext - El contexto acumulado hasta el momento.
 * @param {string} newEvidence - La nueva evidencia encontrada por el agente actual.
 * @param {string[]} apiKeys - Lista de claves API para rotaci√≥n.
 * @returns {Promise<string>} El nuevo contexto resumido.
 */
async function summarizeContext(query, prevContext, newEvidence, apiKeys) {
  const model = "openrouter/bert-nebulon-alpha"; // Modelo ligero y gratuito

  // Asegurar que newEvidence sea string
  const evidenceText = typeof newEvidence === 'string' ? newEvidence : JSON.stringify(newEvidence);

  // Extraer IDs de leyes ya encontradas en la evidencia acumulada
  const foundIds = [...evidenceText.matchAll(/Ley ID (\d+)/g)].map(m => m[1]);
  const prevIds = (typeof prevContext === 'object' && prevContext.found_ids) ? prevContext.found_ids : [];
  const allIds = [...new Set([...prevIds, ...foundIds])];

  // Extraer el resumen de texto del contexto previo (si es objeto) o usarlo directo si es string
  const prevSummary = (typeof prevContext === 'object' && prevContext.resumen_actual)
    ? prevContext.resumen_actual
    : (prevContext || "Nada a√∫n.");

  const prompt = `
  Eres un coordinador de investigaci√≥n legal experto.
  
  CONSULTA DEL USUARIO: "${query}"
  
  LO QUE YA SAB√çAMOS (Resumen Previo):
  """
  ${prevSummary}
  """

  LEYES YA ENCONTRADAS (IDs): ${allIds.join(', ')}
  
  NUEVOS HALLAZGOS (Agente Actual):
  """
  ${newEvidence}
  """
  
  TU TAREA:
  1. Analiza si los nuevos hallazgos responden lo que faltaba.
  2. Genera un nuevo resumen consolidado (M√ÅXIMO 200 PALABRAS).
  3. Detecta qu√© conceptos CLAVE faltan.
  4. Formula una instrucci√≥n POSITIVA detallada y una CORTA (< 15 palabras) para agentes simples.
  5. Genera restricciones expl√≠citas (incluyendo IDs de leyes ya encontradas).
  
  SALIDA (Formato JSON):
  {
    "resumen_actual": "Texto consolidado (max 200 palabras)...",
    "conceptos_faltantes": ["Concepto A", "Concepto B"],
    "instruccion_busqueda": "Instrucci√≥n detallada...",
    "instruccion_corta": "Instrucci√≥n simple (ej: 'Busca plazos de vacaciones')",
    "restricciones_busqueda": "NO busques X. NO descargues Leyes con ID: [Lista IDs]",
    "found_ids": [${allIds.join(', ')}]
  }
  Responde SOLO con JSON v√°lido.
  `;

  for (const apiKey of apiKeys) {
    try {
      const openai = new OpenAI({
        baseURL: 'https://openrouter.ai/api/v1',
        apiKey: apiKey,
        defaultHeaders: {
          'HTTP-Referer': 'https://github.com/gemini-mcp',
          'X-Title': 'Gemini MCP Legal Agent',
        },
      });

      const completion = await openai.chat.completions.create({
        model: model,
        messages: [{ role: "user", content: prompt }],
        temperature: 0.2,
        response_format: { type: "json_object" }
      });

      const responseContent = completion.choices[0].message.content;
      logNebulonInteraction(prompt, responseContent);

      return JSON.parse(responseContent);

    } catch (error) {
      console.warn(`[Orquestador] ‚ö†Ô∏è Error al resumir contexto con Nebulon (Key ${apiKey.substring(0, 8)}...): ${error.message}`);
    }
  }

  // Fallback en caso de error total
  return {
    resumen_actual: prevSummary + "\n" + newEvidence,
    conceptos_faltantes: ["Desconocido"],
    instruccion_busqueda: "Contin√∫a buscando informaci√≥n relevante sobre la consulta.",
    instruccion_corta: "Busca informaci√≥n relevante.",
    restricciones_busqueda: "Ninguna."
  };
}

/**
 * Utiliza Nebulon para extraer citas relevantes y estructurar la evidencia cruda.
 * @param {string} query - La consulta del usuario.
 * @param {string} rawEvidence - El texto crudo de la ley encontrada.
 * @param {string[]} apiKeys - Lista de claves API.
 * @returns {Promise<string>} Evidencia procesada y limpia.
 */
async function extractEvidence(query, rawEvidence, apiKeys) {
  const model = "openrouter/bert-nebulon-alpha"; // Modelo eficiente para extracci√≥n

  // Nebulon tiene un contexto de ~256k tokens (~1M caracteres).
  // Ajustamos el l√≠mite de seguridad a 1.000.000 caracteres.
  const truncatedEvidence = rawEvidence.length > 1000000
    ? rawEvidence.substring(0, 1000000) + "\n[...TRUNCADO POR SEGURIDAD (1M chars)...]"
    : rawEvidence;

  const prompt = `
  Eres un analista legal experto. Tu tarea es extraer informaci√≥n relevante de un texto legal crudo para responder a una consulta espec√≠fica.
  
  CONSULTA DEL USUARIO: "${query}"
  
  TEXTO LEGAL CRUDO:
  """
  ${truncatedEvidence}
  """
  
  INSTRUCCIONES:
  1. Analiza el texto legal buscando art√≠culos o secciones que respondan DIRECTAMENTE a la consulta.
  2. Extrae las CITAS TEXTUALES clave.
  3. Genera un resumen conciso de lo encontrado.
  4. Si el texto no es relevante para la consulta, ind√≠calo.
  
  SALIDA (Formato JSON):
  {
    "relevancia": "ALTA" | "MEDIA" | "BAJA" | "NULA",
    "resumen": "Breve explicaci√≥n de lo encontrado...",
    "citas_clave": ["Art. X: ...", "Art. Y: ..."],
    "observaciones": "Cualquier nota adicional sobre la vigencia o contexto."
  }
  Responde SOLO con el JSON v√°lido.
  `;

  for (const apiKey of apiKeys) {
    try {
      const openai = new OpenAI({
        baseURL: 'https://openrouter.ai/api/v1',
        apiKey: apiKey,
        defaultHeaders: {
          'HTTP-Referer': 'https://github.com/gemini-mcp',
          'X-Title': 'Gemini MCP Legal Agent',
        },
      });

      const completion = await openai.chat.completions.create({
        model: model,
        messages: [{ role: "user", content: prompt }],
        temperature: 0.1, // Bajo para precisi√≥n
        response_format: { type: "json_object" }
      });

      const responseContent = completion.choices[0].message.content;
      logNebulonInteraction(`[EXTRACCI√ìN] ${prompt.substring(0, 200)}...`, responseContent);

      return responseContent;

    } catch (error) {
      console.warn(`[Orquestador] ‚ö†Ô∏è Error en extracci√≥n con Nebulon: ${error.message}`);
    }
  }

  // Fallback: devolver un resumen manual si falla Nebulon
  return JSON.stringify({
    relevancia: "DESCONOCIDA (Fallo Nebulon)",
    resumen: "No se pudo procesar la evidencia con IA. Se adjunta texto crudo truncado.",
    citas_clave: [truncatedEvidence.substring(0, 1000) + "..."],
    observaciones: "Error en procesamiento."
  });
}

/**
 * Resume una ley completa utilizando Nebulon para prepararla para el Agente Razonador.
 * @param {string} lawText - El texto completo de la ley.
 * @param {string[]} apiKeys - Lista de claves API.
 * @returns {Promise<string>} El resumen detallado de la ley.
 */
async function summarizeLawWithNebulon(lawText, apiKeys) {
  const model = "openrouter/bert-nebulon-alpha"; // Usar el modelo designado como Nebulon

  // Truncar si es excesivamente largo para Nebulon (aunque se espera que maneje contextos razonables)
  const truncatedText = lawText.length > 200000
    ? lawText.substring(0, 200000) + "\n[...TRUNCADO...]"
    : lawText;

  const prompt = `
  Eres un experto legal (Nebulon). Genera un resumen estructurado de esta ley para Gemini 3.0.
  
  TEXTO:
  """
  ${truncatedText}
  """
  
  SALIDA (JSON):
  {
    "titulo": "T√≠tulo de la Ley/Norma",
    "resumen_detallado": "Resumen exhaustivo...",
    "fragmentos_clave": ["Cita 1", "Cita 2"]
  }
  `;

  for (const apiKey of apiKeys) {
    try {
      const openai = new OpenAI({
        baseURL: 'https://openrouter.ai/api/v1',
        apiKey: apiKey,
        defaultHeaders: { 'HTTP-Referer': 'https://github.com/gemini-mcp', 'X-Title': 'Gemini MCP Legal Agent' },
      });

      const completion = await openai.chat.completions.create({
        model: model,
        messages: [{ role: "user", content: prompt }],
        temperature: 0.4, // Temperatura ajustada a 0.4
        response_format: { type: "json_object" }
      });

      const content = completion.choices[0].message.content;
      logNebulonInteraction(`[RESUMEN JSON]`, content);
      return JSON.parse(content); // Retornar objeto, no string

    } catch (error) {
      console.warn(`[Orquestador] ‚ö†Ô∏è Error Nebulon: ${error.message}`);
    }
  }

  return { error: "Fallo al resumir", texto_parcial: lawText.substring(0, 1000) };
}

/**
 * Ejecuta el flujo principal de orquestaci√≥n.
 * 1. Selecciona el grupo de agentes buscadores.
 * 2. Lanza las b√∫squedas en paralelo.
 * 3. Recopila y combina la evidencia encontrada.
 * 4. Env√≠a la evidencia al agente razonador para generar la respuesta final.
 * 
 * @async
 * @param {string} userQuery - La consulta legal del usuario.
 * @param {string} [groupId='1'] - El ID del grupo de agentes a utilizar ('1' o '2').
 * @returns {Promise<string|undefined>} La respuesta final generada por el agente razonador, o undefined si hay errores cr√≠ticos.
 */
async function runOrchestrator(userQuery, groupId = '1') {
  logger.startNewSession(); // Iniciar nuevo archivo de log para esta consulta
  logger.info(`\n[Orquestador] üöÄ Iniciando Orquestador de Agentes Legales`);
  logger.info(`[Orquestador] üìã Consulta del usuario: "${userQuery}"`);
  logger.info(`[Orquestador] üë• Grupo de agentes seleccionado: ${groupId}`);
  logger.info(`[Orquestador] üìÅ Archivo de logs: ${logger.getLogFilePath()}`);

  let selectedGroup = SEARCHER_GROUPS[groupId];
  if (!selectedGroup) {
    logger.error(`Error: El grupo de buscadores con ID '${groupId}' no existe. Usando Grupo 1 por defecto.`);
    selectedGroup = SEARCHER_GROUPS['1'];
  }

  // Obtener API Keys del entorno (soporta lista separada por comas)
  const envKeys = process.env.OPENROUTER_API_KEYS || process.env.OPENROUTER_API_KEY;
  const apiKeys = envKeys ? envKeys.split(',').map(k => k.trim()).filter(k => k.length > 0) : [];

  if (apiKeys.length === 0) {
    logger.error("Error: No se encontraron claves API en OPENROUTER_API_KEYS o OPENROUTER_API_KEY.");
    return;
  }

  logger.info(`[Orquestador] ${selectedGroup.length} agentes buscadores activos en el Grupo ${groupId}.`);

  let evidenceList = []; // Array para acumular objetos de evidencia estructurada
  let previousFindings = "";

  // Ejecuci√≥n Secuencial Colaborativa
  for (let i = 0; i < selectedGroup.length; i++) {
    const agentConfig = selectedGroup[i];
    logger.info(`\n[Orquestador] üöÄ Desplegando Agente Buscador ${i + 1}/${selectedGroup.length} con modelos: ${agentConfig.models.join(", ")}`);

    // Construir Prompt Din√°mico con Contexto Previo
    let currentSystemPrompt = searcherSystemPrompt;
    let instruccionFinal = null;

    // Si hay hallazgos previos (objeto JSON de Nebulon o string inicial)
    if (previousFindings) {
      const resumen = previousFindings.resumen_actual || previousFindings; // Manejar objeto o string
      const instruccion = previousFindings.instruccion_busqueda || "";
      const instruccionCorta = previousFindings.instruccion_corta || instruccion;
      const restricciones = previousFindings.restricciones_busqueda || "";

      // Detectar si es un modelo "peque√±o" o propenso a fallar con instrucciones largas
      // Asumimos que el Grupo 2 (Nemotron/Nano) se beneficia de instrucciones cortas
      const isSmallModel = agentConfig.models.some(m => m.includes("nano") || m.includes("mobile"));
      instruccionFinal = isSmallModel ? instruccionCorta : instruccion;

      logger.info(`[Orquestador] üß† Inyectando contexto previo al Agente ${i + 1}...`);

      currentSystemPrompt += `
      
      --- CONTEXTO DE COLABORACI√ìN ---
      
      OBJETIVO FINAL: Responder a la consulta del usuario: "${userQuery}"
      
      ESTADO ACTUAL DE LA INVESTIGACI√ìN:
      Otros agentes ya han encontrado lo siguiente:
      """
      ${resumen}
      """
      `;

      if (instruccionFinal) {
        logger.info(`[Orquestador] üí° Nebulon sugiere (${isSmallModel ? 'CORTA' : 'DETALLADA'}): "${instruccionFinal}"`);
        currentSystemPrompt += `
        ‚ö†Ô∏è INSTRUCCI√ìN PRIORITARIA DEL COORDINADOR:
        "${instruccionFinal}"
        
        ‚õî RESTRICCIONES (LO QUE YA TENEMOS):
        "${restricciones}"
        
        C√©ntrate en cumplir la instrucci√≥n positiva y RESPETAR las restricciones.
        `;
      } else {
        currentSystemPrompt += `
        TU MISI√ìN:
        1. Analiza la consulta del usuario frente a la evidencia ya encontrada.
        2. Detecta qu√© informaci√≥n CLAVE falta.
        3. Busca EXCLUSIVAMENTE esa informaci√≥n faltante.
        `;
      }
    }

    try {
      // --- L√ìGICA DE AISLAMIENTO DE CONTEXTO ---
      // Definir la instrucci√≥n activa (lo que el agente debe hacer AHORA)
      let activeInstruction = userQuery; // Por defecto (primer agente) es la query original
      if (instruccionFinal) {
        activeInstruction = instruccionFinal; // Si Nebulon dio una orden, esa es la ley suprema
      }

      // Definir el contexto pasivo (referencia)
      const contextData = {
        originalQuery: userQuery
      };

      let result = await runSearchAgent(activeInstruction, contextData, currentSystemPrompt, agentConfig.models, apiKeys);

      // --- L√ìGICA DE FALLBACK ROBUSTO (SAFETY NET) ---
      if (result.failed) {
        logger.warn(`[Orquestador] ‚ö†Ô∏è Agente Principal ${i + 1} fall√≥ (4/4 keys). Iniciando Protocolo de Respaldo (Grupo 2)...`);

        // Guardar evidencia parcial si existe
        const partialEvidence = result.evidence;
        if (partialEvidence) {
          logger.info(`[Orquestador] üíæ Evidencia parcial preservada del Agente ${i + 1}.`);
        }

        // Obtener agentes de respaldo (Grupo 2)
        const backupGroup = SEARCHER_GROUPS['2'];
        let backupSuccess = false;

        for (let j = 0; j < backupGroup.length; j++) {
          const backupConfig = backupGroup[j];
          logger.info(`[Orquestador] üõ°Ô∏è Activando Agente de Respaldo ${j + 1}/${backupGroup.length} (Modelos: ${backupConfig.models.join(", ")})...`);

          const backupResult = await runSearchAgent(activeInstruction, contextData, currentSystemPrompt, backupConfig.models, apiKeys);

          if (!backupResult.failed) {
            logger.info(`[Orquestador] ‚úÖ Agente de Respaldo ${j + 1} tuvo √©xito. Recuperaci√≥n completada.`);
            result = backupResult; // Reemplazar resultado fallido con el exitoso
            backupSuccess = true;
            break; // Salir del bucle de respaldo
          } else {
            logger.warn(`[Orquestador] ‚ùå Agente de Respaldo ${j + 1} tambi√©n fall√≥.`);
          }
        }

        if (!backupSuccess) {
          logger.error(`[Orquestador] üíÄ Todos los agentes de respaldo fallaron. Volviendo a evidencia parcial (si existe).`);
          // Si todo falla, nos quedamos con la evidencia parcial del agente original (o string vac√≠o)
          result.evidence = partialEvidence || "";
        }
      }

      if (result && result.evidence) {
        logger.info(`[Orquestador] ‚úÖ Evidencia recibida de ${result.model}.`);

        // --- Resumir la ley con Nebulon (JSON) ---
        logger.info(`[Orquestador] üß† Nebulon est√° estructurando la evidencia...`);
        const evidenceObject = await summarizeLawWithNebulon(result.evidence, apiKeys);

        // Agregar metadatos del agente fuente
        evidenceObject.source_agent = result.model;
        evidenceList.push(evidenceObject);

        // Actualizar contexto usando Nebulon (para el bucle de b√∫squeda)
        // Nota: summarizeContext espera texto, as√≠ que le pasamos el resumen del objeto
        const textForContext = evidenceObject.resumen_detallado || JSON.stringify(evidenceObject);

        logger.info(`[Orquestador] üß† Sintetizando contexto con Nebulon...`);
        const summaryObj = await summarizeContext(userQuery, previousFindings, textForContext, apiKeys);
        previousFindings = summaryObj;

        logger.debug(`[Orquestador] üìù Nuevo Contexto Resumido: ${JSON.stringify(previousFindings).substring(0, 200)}...`);

      } else {
        logger.warn(`[Orquestador] ‚ö†Ô∏è Agente ${i + 1} (y sus respaldos) no encontraron evidencia nueva.`);
      }
    } catch (err) {
      logger.error(`[Orquestador] ‚ùå Error CR√çTICO en ciclo de Agente ${i + 1}: ${err.message}`);
    }
  }

  /* 
  // L√≥gica anterior paralela (comentada/reemplazada)
  const searchPromises = selectedGroup.map(agentConfig => { ... });
  const settlementResults = await Promise.allSettled(searchPromises);
  ...
  */

  if (evidenceList.length === 0) {
    logger.warn("[Orquestador] Ning√∫n agente buscador encontr√≥ informaci√≥n relevante.");
    return "Lo siento, no pude encontrar informaci√≥n relevante sobre tu consulta en la base de datos de Ley Chile.";
  }

  logger.info("\n--- [Orquestador] Evidencia Recopilada ---");
  logger.info(`[Orquestador] üìä N√∫mero de piezas de evidencia: ${evidenceList.length}`);
  logger.debug(JSON.stringify(evidenceList[0]).substring(0, 500) + "...");
  logger.info("--- [Orquestador] Fin de la Evidencia ---");

  // --- FASE DE REFINAMIENTO (GAP FILLER) ---
  // Bucle: Mientras Nebulon detecte conceptos faltantes, activamos al Gap Filler.
  let gapFillerAttempts = 0;
  const MAX_GAP_FILLER_ATTEMPTS = 5; // L√≠mite de seguridad para evitar bucles infinitos

  while (
    previousFindings &&
    previousFindings.conceptos_faltantes &&
    previousFindings.conceptos_faltantes.length > 0 &&
    gapFillerAttempts < MAX_GAP_FILLER_ATTEMPTS
  ) {
    gapFillerAttempts++;
    logger.info(`\n[Orquestador] üïµÔ∏è Activando Gap Filler (Ciclo ${gapFillerAttempts}/${MAX_GAP_FILLER_ATTEMPTS}). Conceptos: ${previousFindings.conceptos_faltantes.join(", ")}`);

    const gapResult = await runGapFillerAgent(previousFindings.conceptos_faltantes, previousFindings, userQuery);

    if (gapResult.evidence) {
      logger.info(`[Orquestador] ‚úÖ Gap Filler retorn√≥ evidencia. Actualizando Nebulon...`);

      // Si Gap Filler retorna evidencia, tambi√©n la resumimos y agregamos
      const gapEvidenceObject = await summarizeLawWithNebulon(gapResult.evidence, apiKeys);
      gapEvidenceObject.source_agent = `Gap Filler (Ciclo ${gapFillerAttempts})`;
      evidenceList.push(gapEvidenceObject);

      // Re-evaluar con Nebulon para ver si ya estamos completos
      logger.info(`[Orquestador] üß† Re-evaluando completitud con Nebulon...`);
      const textForContext = gapEvidenceObject.resumen_detallado || JSON.stringify(gapEvidenceObject);
      const newSummary = await summarizeContext(userQuery, previousFindings, textForContext, apiKeys);
      previousFindings = newSummary;

      if (!previousFindings.conceptos_faltantes || previousFindings.conceptos_faltantes.length === 0) {
        logger.info(`[Orquestador] üéâ Nebulon indica que NO faltan conceptos. Refinamiento completado.`);
        break;
      }
    } else {
      logger.warn(`[Orquestador] ‚ö†Ô∏è Gap Filler no encontr√≥ nueva evidencia. Terminando refinamiento para evitar redundancia.`);
      break;
    }
  }

  logger.info("\n[Orquestador] Enviando evidencia a Gemini para la s√≠ntesis final...");

  // --- CONSTRUCCI√ìN DEL SUPER CONTEXTO (JSON String) ---
  const superContext = JSON.stringify({
    original_requirement: userQuery,
    searched_concepts: previousFindings ? previousFindings.found_ids : [],
    missing_concepts: previousFindings ? previousFindings.conceptos_faltantes : [],
    evidence_collection: evidenceList
  }, null, 2);

  // Truncar si es necesario (aunque JSON stringificado es texto)
  const truncatedContext = superContext.length > 300000
    ? superContext.substring(0, 300000) + "\n...[TRUNCADO]..."
    : superContext;


  logger.info(`[Orquestador] üì¶ Super Contexto preparado (${truncatedContext.length} caracteres).`);

  const finalResponse = await runReasonerAgent(userQuery, reasonerSystemPrompt, truncatedContext);

  logger.info("\n\n--- ASESOR√çA LEGAL FINAL ---");
  console.log(finalResponse);
  logger.info("---------------------------\n");

  return finalResponse;
}

export { runOrchestrator };
