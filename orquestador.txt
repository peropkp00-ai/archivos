import OpenAI from 'openai';
import { logger } from '../utils/logger.js';
import "dotenv/config";

/**
 * @fileoverview Rol: Jefe de Paralegales (Nebulon).
 * Responsabilidades:
 * 1. Resumir y sintetizar el contexto de investigación.
 * 2. Extraer evidencia estructurada de textos legales crudos.
 * 3. Coordinar a los investigadores (agentes).
 * 
 * Refinado para cumplir con los estándares de OpenRouter.
 */

// Usamos un modelo rápido y capaz de OpenRouter.
// 'google/gemini-2.0-flash-exp:free' es una excelente opción por velocidad y ventana de contexto.
const MODEL_NAME = "google/gemini-2.0-flash-exp:free";

const OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1";
const SITE_URL = "https://github.com/gemini-mcp"; // URL de referencia para el ranking de OpenRouter
const SITE_NAME = "Gemini MCP Legal Agent";

// --- CONFIGURACIÓN DE GRUPOS DE AGENTES (Regla Inmutable) ---
export const SEARCHER_GROUPS = {
    '1': [
        { models: ["x-ai/grok-4.1-fast"] },
        { models: ["z-ai/glm-4.5-air:free"] },
        { models: ["meta-llama/llama-3.3-70b-instruct:free"] },
        { models: ["kwaipilot/kat-coder-pro:free"] },
    ],
    '2': [
        { models: ["meituan/longcat-flash-chat:free"] },
        { models: ["openai/gpt-oss-20b:free"] },
        { models: ["alibaba/tongyi-deepresearch-30b-a3b:free"] },
        { models: ["google/gemini-2.0-flash-exp:free"] },
    ]
};

/**
 * Crea una instancia configurada del cliente OpenAI para OpenRouter.
 * @param {string} apiKey - Clave API de OpenRouter.
 * @returns {OpenAI} Instancia del cliente.
 */
function createOpenRouterClient(apiKey) {
    return new OpenAI({
        baseURL: OPENROUTER_BASE_URL,
        apiKey: apiKey,
        defaultHeaders: {
            'HTTP-Referer': SITE_URL,
            'X-Title': SITE_NAME,
        },
    });
}

/**
 * Utiliza un modelo ligero para resumir y estructurar el contexto entre agentes.
 * @param {string} query - La consulta original del usuario.
 * @param {string} prevContext - El contexto acumulado hasta el momento.
 * @param {string} newEvidence - La nueva evidencia encontrada por el agente actual.
 * @param {string[]} apiKeys - Lista de claves API para rotación.
 * @returns {Promise<Object>} El nuevo contexto resumido.
 */
export async function summarizeContext(query, prevContext, newEvidence, apiKeys) {
    // Asegurar que newEvidence sea string
    const evidenceText = typeof newEvidence === 'string' ? newEvidence : JSON.stringify(newEvidence);

    // Extraer IDs de leyes ya encontradas en la evidencia acumulada
    const foundIds = [...evidenceText.matchAll(/Ley ID (\d+)/g)].map(m => m[1]);
    const prevIds = (typeof prevContext === 'object' && prevContext.found_ids) ? prevContext.found_ids : [];
    const allIds = [...new Set([...prevIds, ...foundIds])];

    // Extraer el resumen de texto del contexto previo
    const prevSummary = (typeof prevContext === 'object' && prevContext.resumen_actual)
        ? prevContext.resumen_actual
        : (prevContext || "Nada aún.");

    const prompt = `
  Eres un coordinador de investigación legal experto (Jefe de Paralegales).
  
  CONSULTA DEL USUARIO: "${query}"
  
  LO QUE YA SABÍAMOS (Resumen Previo):
  """
  ${prevSummary}
  """

  LEYES YA ENCONTRADAS (IDs): ${allIds.join(', ')}
  
  NUEVOS HALLAZGOS (Agente Actual):
  """
  ${evidenceText}
  """
  
  TU TAREA:
  1. Analiza si los nuevos hallazgos responden lo que faltaba.
  2. Genera un nuevo resumen consolidado (MÁXIMO 200 PALABRAS).
  3. Detecta qué conceptos CLAVE faltan.
  4. Formula una instrucción POSITIVA detallada y una CORTA (< 15 palabras) para agentes simples.
  5. Genera restricciones explícitas (incluyendo IDs de leyes ya encontradas).
  
  SALIDA (Formato JSON):
  {
    "resumen_actual": "Texto consolidado (max 200 palabras)...",
    "conceptos_faltantes": ["Concepto A", "Concepto B"],
    "instruccion_busqueda": "Instrucción detallada...",
    "instruccion_corta": "Instrucción simple (ej: 'Busca plazos de vacaciones')",
    "restricciones_busqueda": "NO busques X. NO descargues Leyes con ID: [Lista IDs]",
    "found_ids": [${allIds.join(', ')}]
  }
  Responde SOLO con JSON válido.
  `;

    for (const apiKey of apiKeys) {
        try {
            const openai = createOpenRouterClient(apiKey);

            const completion = await openai.chat.completions.create({
                model: MODEL_NAME,
                messages: [{ role: "user", content: prompt }],
                temperature: 0.2,
                response_format: { type: "json_object" }
            });

            const responseContent = completion.choices[0].message.content;

            // Log detallado usando el nuevo logger
            logger.logFullPayload('03_nebulon_audit.log', 'SUMMARIZE_CONTEXT', {
                input: prompt,
                output: responseContent
            });

            return JSON.parse(responseContent);

        } catch (error) {
            logger.warn(`[Nebulon] ⚠️ Error al resumir contexto (Key ${apiKey.substring(0, 8)}...): ${error.message}`);
        }
    }

    // Fallback
    return {
        resumen_actual: prevSummary + "\n" + evidenceText,
        conceptos_faltantes: ["Desconocido (Fallo Nebulon)"],
        instruccion_busqueda: "Continúa buscando información relevante.",
        instruccion_corta: "Busca información relevante.",
        restricciones_busqueda: "Ninguna.",
        found_ids: allIds
    };
}

/**
 * Utiliza Nebulon para extraer citas relevantes y estructurar la evidencia cruda.
 * @param {string} query - La consulta del usuario.
 * @param {string} rawEvidence - El texto crudo de la ley encontrada.
 * @param {string[]} apiKeys - Lista de claves API.
 * @returns {Promise<string>} Evidencia procesada y limpia (JSON String).
 */
export async function extractEvidence(query, rawEvidence, apiKeys) {
    // Truncado de seguridad (1M caracteres)
    const truncatedEvidence = rawEvidence.length > 1000000
        ? rawEvidence.substring(0, 1000000) + "\n[...TRUNCADO POR SEGURIDAD (1M chars)...]"
        : rawEvidence;

    const prompt = `
  Eres un analista legal experto. Tu tarea es extraer información relevante de un texto legal crudo para responder a una consulta específica.
  
  CONSULTA DEL USUARIO: "${query}"
  
  TEXTO LEGAL CRUDO:
  """
  ${truncatedEvidence}
  """
  
  INSTRUCCIONES:
  1. Analiza el texto legal buscando artículos o secciones que respondan DIRECTAMENTE a la consulta.
  2. Extrae las CITAS TEXTUALES clave.
  3. Genera un resumen conciso de lo encontrado.
  4. Si el texto no es relevante para la consulta, indícalo.
  
  SALIDA (Formato JSON):
  {
    "relevancia": "ALTA" | "MEDIA" | "BAJA" | "NULA",
    "resumen": "Breve explicación de lo encontrado...",
    "citas_clave": ["Art. X: ...", "Art. Y: ..."],
    "observaciones": "Cualquier nota adicional sobre la vigencia o contexto."
  }
  Responde SOLO con el JSON válido.
  `;

    for (const apiKey of apiKeys) {
        try {
            const openai = createOpenRouterClient(apiKey);

            const completion = await openai.chat.completions.create({
                model: MODEL_NAME,
                messages: [{ role: "user", content: prompt }],
                temperature: 0.1,
                response_format: { type: "json_object" }
            });

            const responseContent = completion.choices[0].message.content;

            logger.logFullPayload('03_nebulon_audit.log', 'EXTRACT_EVIDENCE', {
                input: prompt.substring(0, 500) + "... [TRUNCATED]", // Log input truncado para no saturar
                output: responseContent
            });

            return responseContent;

        } catch (error) {
            logger.warn(`[Nebulon] ⚠️ Error en extracción: ${error.message}`);
        }
    }

    return JSON.stringify({
        relevancia: "DESCONOCIDA (Fallo Nebulon)",
        resumen: "No se pudo procesar la evidencia con IA. Se adjunta texto crudo truncado.",
        citas_clave: [truncatedEvidence.substring(0, 1000) + "..."],
        observaciones: "Error en procesamiento."
    });
}

/**
 * Resume una ley completa utilizando Nebulon para prepararla para el Abogado Senior.
 * @param {string} lawText - El texto completo de la ley.
 * @param {string[]} apiKeys - Lista de claves API.
 * @returns {Promise<Object>} El resumen detallado de la ley.
 */
export async function summarizeLaw(lawText, apiKeys) {
    const truncatedText = lawText.length > 200000
        ? lawText.substring(0, 200000) + "\n[...TRUNCADO...]"
        : lawText;

    const prompt = `
  Eres un experto legal (Nebulon). Genera un resumen estructurado de esta ley para el Abogado Senior.
  
  TEXTO:
  """
  ${truncatedText}
  """
  
  SALIDA (JSON):
  {
    "titulo": "Título de la Ley/Norma",
    "resumen_detallado": "Resumen exhaustivo...",
    "fragmentos_clave": ["Cita 1", "Cita 2"]
  }
  `;

    for (const apiKey of apiKeys) {
        try {
            const openai = createOpenRouterClient(apiKey);

            const completion = await openai.chat.completions.create({
                model: MODEL_NAME,
                messages: [{ role: "user", content: prompt }],
                temperature: 0.4,
                response_format: { type: "json_object" }
            });

            const content = completion.choices[0].message.content;

            logger.logFullPayload('03_nebulon_audit.log', 'SUMMARIZE_LAW', {
                input_length: truncatedText.length,
                output: content
            });

            return JSON.parse(content);

        } catch (error) {
            logger.warn(`[Nebulon] ⚠️ Error al resumir ley: ${error.message}`);
        }
    }

    return { error: "Fallo al resumir", texto_parcial: lawText.substring(0, 1000) };
}
